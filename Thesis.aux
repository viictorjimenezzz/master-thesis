\relax 
\@writefile{toc}{\contentsline {chapter}{Abstract}{v}{}\protected@file@percent }
\newlabel{chap:symbole}{{}{vii}}
\@writefile{toc}{\contentsline {chapter}{Notation}{vii}{}\protected@file@percent }
\citation{p.murphyProbabilisticMachineLearning2022}
\citation{m.bishopPatternRecognitionMachine2006}
\citation{quinonero-candelaDatasetShiftMachine2009}
\citation{buhmannPosteriorAgreementModel2022}
\citation{szegedyIntriguingPropertiesNeural2014}
\citation{tsiprasRobustnessMayBe2019}
\citation{quinonero-candelaDatasetShiftMachine2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:introduction}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The robustness challenge}{1}{}\protected@file@percent }
\newlabel{sec:motivation}{{1.1}{1}}
\citation{jimenezInductiveBiasDeep}
\citation{tsiprasRobustnessMayBe2019}
\citation{zhangTheoreticallyPrincipledTradeoff2019}
\citation{ilyasAdversarialExamplesAre2019}
\citation{szegedyIntriguingPropertiesNeural2014}
\citation{goodfellowExplainingHarnessingAdversarial2015}
\citation{baiRecentAdvancesAdversarial2021}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Illustrative example of the three expected sources of variability. A pre-trained MobileNetV2 model is shown to be vulnerable to adversarial perturbations as the one represented in (c), and also to distribution shifts as the one illustrated in (d), possibly because its inductive bias is influenced by the spurious correlation between cows and rural landscapes.\relax }}{2}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:cows}{{1.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Adversarial setting}{2}{}\protected@file@percent }
\citation{schmidtAdversariallyRobustGeneralization2018}
\citation{tsiprasRobustnessMayBe2019}
\citation{zhangTheoreticallyPrincipledTradeoff2019}
\citation{madryDeepLearningModels2019}
\citation{madryDeepLearningModels2019}
\citation{ilyasAdversarialExamplesAre2019}
\citation{tsiprasRobustnessMayBe2019}
\citation{tsiprasRobustnessMayBe2019}
\citation{tsiprasRobustnessMayBe2019}
\citation{tsiprasRobustnessMayBe2019}
\citation{tsiprasRobustnessMayBe2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  A conceptual illustration of standard vs. adversarial decision boundaries. (\textbf  {left}) A set of linearly-separable points. (\textbf  {middle}) Decision boundary learned via standard training. (\textbf  {right}) Decision boundary learned via adversarial training. Both methods achieve zero training error, but only the robust model is able to generalize to $\ell _\infty $ perturbations. \cite  {madryDeepLearningModels2019} \relax }}{3}{}\protected@file@percent }
\newlabel{fig:adversarial_complexity}{{1.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Scaled loss gradient with respect to input images. Input pixels yielding the highest predictive power are aligned with perceptually relavant features for the case of adversarial models, while appearing completely random in the case of standard models. \cite  {tsiprasRobustnessMayBe2019}\relax }}{3}{}\protected@file@percent }
\newlabel{fig:adversarial_loss}{{1.3}{3}}
\citation{muandetDomainGeneralizationInvariant2013}
\citation{quinonero-candelaDatasetShiftMachine2009}
\citation{zhouDomainGeneralizationSurvey2022}
\citation{wangGeneralizingUnseenDomains2022}
\citation{liuOutOfDistributionGeneralizationSurvey2023}
\citation{kohWILDSBenchmarkIntheWild2021}
\citation{kohWILDSBenchmarkIntheWild2021}
\citation{torralbaUnbiasedLookDataset2011}
\citation{torralbaUnbiasedLookDataset2011}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Adversarial examples for standard and adversarially-trained models. Perturbed images produced for robust models effectively capture salient data characteristics. \cite  {tsiprasRobustnessMayBe2019}\relax }}{4}{}\protected@file@percent }
\newlabel{fig:salient_characteristics}{{1.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Out-of-distribution setting}{4}{}\protected@file@percent }
\newlabel{sec:intro_ood}{{1.1.2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces The \texttt  {camelyon17} (WILDS) dataset comprises images of stained lymph node tissue patches sampled from different hospitals. \cite  {kohWILDSBenchmarkIntheWild2021} \relax }}{4}{}\protected@file@percent }
\newlabel{fig:camelyon17}{{1.5}{4}}
\citation{wangGeneralizingUnseenDomains2022}
\citation{wangGeneralizingUnseenDomains2022}
\citation{liuOutOfDistributionGeneralizationSurvey2023}
\citation{blanchardGeneralizingSeveralRelated}
\citation{shenWassersteinDistanceGuided2018}
\citation{liangComprehensiveSurveyTestTime2023}
\citation{muandetDomainGeneralizationInvariant2013}
\citation{muandetDomainGeneralizationInvariant2013}
\citation{zhangMixupEmpiricalRisk2018}
\citation{zhangMixupEmpiricalRisk2018}
\citation{yunCutMixRegularizationStrategy2019}
\citation{yunCutMixRegularizationStrategy2019}
\citation{yunCutMixRegularizationStrategy2019}
\citation{yunCutMixRegularizationStrategy2019}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces  \textbf  {(left)} Confusion matrix generated in a dataset identification task. A clearly pronounced diagonal indicates that each dataset posesses unique traits that make it distinguishable from the rest. \textbf  {(right)} Cross-dataset generalization for \texttt  {car} detection as function of training data. The vertical gap between lines represents the decrease in performance when training on a different dataset, and the horizontal shift corresponds to the increase in the amount of data needed to reach the same performance. \cite  {torralbaUnbiasedLookDataset2011}\relax }}{5}{}\protected@file@percent }
\newlabel{fig:dataset_bias}{{1.6}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces  Projections of a binary synthetic dataset in the two principal DICA dimensions. The shaded box depicts the projection of training data, whereas the unshaded boxes show projections of unseen test datasets. \cite  {muandetDomainGeneralizationInvariant2013} \relax }}{5}{}\protected@file@percent }
\newlabel{fig:dica}{{1.7}{5}}
\citation{zhouDomainGeneralizationSurvey2022}
\citation{kohWILDSBenchmarkIntheWild2021}
\citation{szegedyIntriguingPropertiesNeural2014}
\citation{goodfellowExplainingHarnessingAdversarial2015}
\citation{madryDeepLearningModels2019}
\citation{carliniEvaluatingRobustnessNeural2017}
\citation{pintorFastMinimumnormAdversarial2021}
\citation{liReviewAdversarialAttack2022}
\citation{baiRecentAdvancesAdversarial2021}
\citation{liReviewAdversarialAttack2022}
\citation{xiaoGeneratingAdversarialExamples2019}
\citation{miyatoVirtualAdversarialTraining2018}
\citation{wangBetterDiffusionModels2023}
\citation{hoDenoisingDiffusionProbabilistic2020}
\citation{cohenCertifiedAdversarialRobustness2019}
\citation{croceRobustBenchStandardizedAdversarial2021a}
\citation{krizhevskyLearningMultipleLayers}
\citation{wangGeneralizingUnseenDomains2022}
\citation{zhouDomainGeneralizationSurvey2022}
\citation{liuOutOfDistributionGeneralizationSurvey2023}
\citation{yaoImprovingOutofDistributionRobustness2022}
\citation{zhangMixupEmpiricalRisk2018}
\citation{yunCutMixRegularizationStrategy2019}
\citation{arjovskyInvariantRiskMinimization2020}
\citation{muandetDomainGeneralizationInvariant2013}
\citation{arjovskyWassersteinGAN2017}
\citation{peiMultiAdversarialDomainAdaptation}
\citation{liLearningGeneralizeMetaLearning2018}
\citation{wangMetaFineTuningNeural2020}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces  Mixup and Cutmix strategies can be used to interpolate between different labels and/or domains by generating intermediate observations. \cite  {yunCutMixRegularizationStrategy2019} \relax }}{6}{}\protected@file@percent }
\newlabel{fig:data_augmentation}{{1.8}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Related work}{6}{}\protected@file@percent }
\citation{guoComprehensiveEvaluationFramework2023}
\citation{wengEvaluatingRobustnessNeural2018}
\citation{wangGeometricalApproachEvaluate2023}
\citation{buhmannPosteriorAgreementModel2022}
\citation{lecun1998mnist}
\citation{euligDiagViB6DiagnosticBenchmark2021}
\citation{yuPACSDatasetPhysical2022}
\citation{khoslaUndoingDamageDataset2012}
\citation{kohWILDSBenchmarkIntheWild2021}
\citation{croceRobustBenchStandardizedAdversarial2021a}
\citation{kohWILDSBenchmarkIntheWild2021}
\citation{euligDiagViB6DiagnosticBenchmark2021}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Objectives}{7}{}\protected@file@percent }
\citation{n.vapnikNatureStatisticalLearning2000}
\citation{casellaStatisticalInference2002}
\citation{gutIntermediateCourseProbability2009}
\citation{n.vapnikNatureStatisticalLearning2000}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theoretical background }{9}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:theory}{{2}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The learning framework}{9}{}\protected@file@percent }
\newlabel{def:dataset}{{2.1}{9}}
\newlabel{def:erm}{{2.1}{9}}
\citation{jimenezInductiveBiasDeep}
\citation{simonyanVeryDeepConvolutional2015}
\citation{n.vapnikNatureStatisticalLearning2000}
\citation{voulodimosDeepLearningComputer2018}
\citation{rumelhartLearningRepresentationsBackpropagating1986}
\citation{ruderOverviewGradientDescent2017}
\citation{kingmaAdamMethodStochastic2017}
\newlabel{def:rrm}{{2.1}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Learning with neural networks}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The output of a node is computed by applying a non-linear activation function $\sigma $ to the weighted sum of its inputs $\bm  {x}$ plus a bias term $b$.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:nn_node}{{2.1}{10}}
\citation{jimenezInductiveBiasDeep}
\citation{buhmannDataScienceAlgorithms2022}
\citation{chehreghaniInformationTheoreticModel}
\citation{buhmannInformationTheoreticModel}
\citation{buhmannInformationTheoreticModel2010}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Posterior agreement}{11}{}\protected@file@percent }
\newlabel{def:data_distribution}{{2.3}{11}}
\citation{lecun1998mnist}
\citation{buhmannDataScienceAlgorithms2022}
\newlabel{def:sample}{{2.3}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Posterior distribution}{12}{}\protected@file@percent }
\newlabel{def:hypothesis_class}{{2.3.1}{12}}
\citation{grunwaldMinimumDescriptionLength2019}
\newlabel{def:posterior}{{2.3.1}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Generalization error}{13}{}\protected@file@percent }
\citation{buhmannDataScienceAlgorithms2022}
\newlabel{lemma:pa}{{2.3.1}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Maximum posterior agreement}{14}{}\protected@file@percent }
\newlabel{def:pa}{{2.3.3}{15}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experimental setup}{17}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:experimental_setup}{{3}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Problem formulation}{17}{}\protected@file@percent }
\newlabel{def:classifier}{{3.1}{17}}
\citation{quinonero-candelaDatasetShiftMachine2009}
\citation{quinonero-candelaDatasetShiftMachine2009}
\citation{quinonero-candelaDatasetShiftMachine2009}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Robustness in covariate shift settings}{18}{}\protected@file@percent }
\newlabel{sec:robustness_to_covariate_shift}{{3.2}{18}}
\newlabel{def:domain_shift}{{3.2}{18}}
\citation{buhmannPosteriorAgreementModel2022}
\newlabel{properties:robustness}{{3.2}{19}}
\citation{szegedyIntriguingPropertiesNeural2014}
\citation{goodfellowExplainingHarnessingAdversarial2015}
\newlabel{example:robustness}{{3.2.1}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Adversarial setting}{20}{}\protected@file@percent }
\newlabel{sec:adversarial_setting}{{3.3}{20}}
\newlabel{def:adversarial_perturbation}{{3.3}{20}}
\citation{goodfellowExplainingHarnessingAdversarial2015}
\citation{goodfellowExplainingHarnessingAdversarial2015}
\citation{madryDeepLearningModels2019}
\citation{madryDeepLearningModels2019}
\citation{pintorFastMinimumnormAdversarial2021}
\citation{liuOutOfDistributionGeneralizationSurvey2023}
\citation{wangGeneralizingUnseenDomains2022}
\newlabel{attack:pgd}{{3.3}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Domain generalization setting}{21}{}\protected@file@percent }
\newlabel{sec:domain_generalization_setting}{{3.4}{21}}
\citation{guoComprehensiveEvaluationFramework2023}
\citation{zhouDomainGeneralizationSurvey2022}
\citation{arjovskyInvariantRiskMinimization2020}
\citation{liuOutOfDistributionGeneralizationSurvey2023}
\citation{arjovskyInvariantRiskMinimization2020}
\citation{arjovskyInvariantRiskMinimization2020}
\citation{zhangMixupEmpiricalRisk2018}
\citation{yunCutMixRegularizationStrategy2019}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Robust learners}{22}{}\protected@file@percent }
\newlabel{sec:robust_learners}{{3.5}{22}}
\citation{yaoImprovingOutofDistributionRobustness2022}
\citation{buhmannPosteriorAgreementModel2022}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Robustness assessment with posterior agreement}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Posterior in classification tasks}{23}{}\protected@file@percent }
\citation{logicofscience}
\citation{bovierStatisticalMechanicsDisordered2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}The posterior agreement kernel}{24}{}\protected@file@percent }
\newlabel{lemma:exchangeability}{{3.6.1}{24}}
\newlabel{theorem:posterior_factorization}{{3.6.2}{25}}
\citation{boydConvexOptimization2004}
\newlabel{theorem:pa_properties}{{3.6.3}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}Implementation}{26}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Robustness assessment}{29}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:robustness_assessment}{{4}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}In-distribution setting}{29}{}\protected@file@percent }
\newlabel{sec:results_robustness}{{4.1}{29}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Comparison of accuracy and PA values for the case $p = 0.5$.\relax }}{29}{}\protected@file@percent }
\newlabel{tab:empirical_table}{{4.1}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Evolution of performance and robustness for the three classifiers\relax }}{30}{}\protected@file@percent }
\newlabel{fig:empirical_plot}{{4.1}{30}}
\citation{maas2011learning}
\citation{sanh2019distilbert}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Evolution of PA kernel optimization under different levels of prediction confidence. An illustration of the original log-odds and its associated posterior distribution can be found in Appendix \ref {subsec:appendix_empirical_behaviour}.\relax }}{31}{}\protected@file@percent }
\newlabel{fig:prediction_confidence}{{4.2}{31}}
\citation{krizhevskyLearningMultipleLayers}
\citation{BMVC2016_87}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces PA and accuracy for the IMDB sentiment classification under Levenshtein perturbations. The attack power is defined as $2^L$, being $L$ the Levenshtein distance between pairs of observations in $\bm  {x}^\prime $ and $\bm  {x}^{\prime }$, respectively.\relax }}{32}{}\protected@file@percent }
\newlabel{fig:imdb_levenshtein}{{4.3}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces PA and accuracy of CIFAR10 classification for increasing levels of white noise.\relax }}{32}{}\protected@file@percent }
\newlabel{fig:gaussian_noise}{{4.4}{32}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces PA kernel optimization in the CIFAR10 gaussian noise setting for different ratio of perturbed samples. Perturbation magnitude is $\ell _\infty $ = 32 / 255.\relax }}{33}{}\protected@file@percent }
\newlabel{fig:gaussian_optimization}{{4.5}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Adversarial setting}{33}{}\protected@file@percent }
\newlabel{sec:results_adversarial}{{4.2}{33}}
\citation{krizhevskyLearningMultipleLayers}
\citation{BMVC2016_87}
\citation{resnet50}
\citation{croceRobustBenchStandardizedAdversarial2021a}
\citation{madryDeepLearningModels2019}
\citation{pintorFastMinimumnormAdversarial2021}
\citation{engstrom2019adversarial}
\citation{AthalyeC018}
\citation{WongRK20}
\citation{Addepalli2022ScalingAT}
\citation{wang2023betterdiffusionmodelsimprove}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Original and adversarially-perturbed CIFAR10 sample of class \texttt  {horse}. Both perturbations succeed at misleading an undefended, pre-trained WideResNet-28-10 net.\relax }}{34}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces  Entropy difference $\Delta H = H(\beta ^{*}) - H(1)$ for different models, obtained for FMN and $\ell _\infty $ = 8/255 PGD attacks, both at $\operatorname  {AR} = 1$. Entropy values are estimated using the average posterior distribution over correctly classified samples, which constitute the largest proportion of the dataset. Figures \ref {fig:pgd_distributions_undefended}-\ref {fig:pgd_distributions_bpda} show the initial and optimal average posteriors from which these values were computed. \relax }}{35}{}\protected@file@percent }
\newlabel{tab:entropy_gibbs}{{4.2}{35}}
\newlabel{thm:approximated_pa}{{4.2.1}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Adversarial robustness assessment with PA}{36}{}\protected@file@percent }
\citation{dasKeepingBadGuys2017}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces PA, AFR(T) and the AFR variation against increasing adversarial ratio at different perturbation norm bounds. The aforementioned undefended net and several RobustBench robust models are considered under a 1000 step PGD attack. When AR = 0, $\operatorname  {PA} \DOTSB \relbar \joinrel \rightarrow 0$ as $\beta \DOTSB \relbar \joinrel \rightarrow \infty $ in all cases, but the convergence rate depends on the prediction confidence (see Figure \ref {fig:prediction_confidence}) and thus yields an assessment equivalent to that of AFR (T). \relax }}{37}{}\protected@file@percent }
\newlabel{fig:six_figures_pa_adv}{{4.7}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces (\textbf  {left}) Average posterior probability of the predicted class for correctly classified original samples, misclassified original samples, and misleading adversarial samples, respectively. (\textbf  {right}) Optimal $\beta ^{*}$ value for each model. Results obtained through a PGD attack with $\ell _\infty = 8 / 255$.\relax }}{38}{}\protected@file@percent }
\newlabel{fig:unrobust_posterior_short_pgd}{{4.8}{38}}
\citation{dasKeepingBadGuys2017}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces PA, AFR(T) and the AFR variation against increasing attack power for $\operatorname  {AR} = 1$. The aforementioned undefended net and several RobustBench robust models are considered under a 1000 step PGD attack.\relax }}{39}{}\protected@file@percent }
\newlabel{fig:pgd_eps}{{4.9}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces PA, AFR(T) and the AFR variation against increasing adversarial ratio. The aforementioned undefended net and several RobustBench robust models are considered under a 1000 step FMN attack.\relax }}{39}{}\protected@file@percent }
\newlabel{fig:adv_fmn_pa_afr}{{4.10}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces (\textbf  {left}) Average posterior probability of the predicted class for correctly classified original samples, misclassified original samples, and misleading adversarial samples, respectively. (\textbf  {right}) Optimal $\beta ^{*}$ value for each model. Results obtained through a FMN attack.\relax }}{40}{}\protected@file@percent }
\newlabel{fig:unrobust_posterior_short_fmn}{{4.11}{40}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces  Comparison of PA, $\operatorname  {AFR}_{\text  {P}}$ and $\operatorname  {AFR}_{\text  {T}}$ scores for a PGD attack with $\ell _\infty $ = 16 / 255 and an FMN attack across different adversarial ratio values. The worst robustness score is emboldened for every case. PA displays higher consistency and discriminative power across varying $\operatorname  {AR}$ with respect to accuracy-based metrics. \relax }}{41}{}\protected@file@percent }
\newlabel{tab:pa_afrpred_comparison_table}{{4.3}{41}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces  Kendall rank correlation coefficient comparing the consistency of the model ranking provided by each metric at different adversarial ratio values. The raking at a specific AR is compared with that with AR = 1.0. PA is shown to display the highest consistency, especially under low attack power settings. \relax }}{41}{}\protected@file@percent }
\newlabel{tab:kendall_comparison_table}{{4.4}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Interpretability of PA in the adversarial setting}{41}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces  Approximated PA contributions for a PGD attack with $\ell _\infty $ = 8/255 and $\operatorname  {AR} = 1.0$. The number of originally misclassified and adversarially misleading samples is $N_{\text  {MIS}} = \lfloor N (1-\operatorname  {AFR}_T^0) \operatorname  {AFR}_P \rfloor $ and $N_{\text  {ADV}} = \lfloor N \operatorname  {AFR}_T^0 (1-\operatorname  {AFR}_P) \rfloor $, respectively. The penalization argument $2 \delta _{\text  {ERR}}$ has not been included for being negligible in all cases. \relax }}{42}{}\protected@file@percent }
\newlabel{tab:approx_pa_pgd_table}{{4.5}{42}}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces  Approximated PA contributions for a FMN attack with $\operatorname  {AR} = 1.0$. The number of originally misclassified and adversarially misleading samples is $N_{\text  {MIS}} = \lfloor N (1-\operatorname  {AFR}_T^0) \operatorname  {AFR}_P \rfloor $ and $N_{\text  {ADV}} = \lfloor N \operatorname  {AFR}_T^0 (1-\operatorname  {AFR}_P) \rfloor $, respectively. The penalization argument $2 \delta _{\text  {ERR}}$ has not been included for being negligible in all cases with the exception of the {\color  {tab:green} \textbf  {Athalye et al.}} model, which amounts to 0.36. \relax }}{43}{}\protected@file@percent }
\newlabel{tab:approx_pa_fmn_table}{{4.6}{43}}
\citation{buhmannDataScienceAlgorithms2022}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces  The two metrics considered are FID, which amounts to the group-based dissimilarity in the feature space, and Wasserstein distance, which measures the average distance between probability distributions. \relax }}{44}{}\protected@file@percent }
\newlabel{fig:adv_metric_comparison}{{4.12}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Out-of-distribution setting}{44}{}\protected@file@percent }
\newlabel{results_domain_generalization}{{4.3}{44}}
\citation{euligDiagViB6DiagnosticBenchmark2021}
\newlabel{def:shifted_factors_experiment}{{4.3}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces  Image factors associated to each of the environments considered in this experiment. CC and LC account for 'centered center' and 'centered low', respectively. \relax }}{46}{}\protected@file@percent }
\newlabel{tab:data_shift_table}{{4.7}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.13}{\ignorespaces  Illustration of the training, validation and test datasets. Samples for each training environment belong to different MNIST subsets, whereas samples of validation and test are corresponding. \relax }}{46}{}\protected@file@percent }
\newlabel{fig:data_shift_images}{{4.13}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.14}{\ignorespaces Evolution of PA under increasing levels of shift power. Weights maximizing validation accuracy were selected for ERM, IRM and LISA algorithms. Results for incremental presence of shifted samples indicate that PA is able to differentiate weak and robust models. \relax }}{47}{}\protected@file@percent }
\newlabel{fig:six_figures}{{4.14}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces  Pairwise cosine similarity between feature space representations of original and augmented images, for each of the shifted datasets. The abrupt decrease in similarity for the fifth environment indicates a discontinuity in the feature representation of images, which leads to non-comparable predictive outcomes. \relax }}{47}{}\protected@file@percent }
\newlabel{tab:CS_shift}{{4.8}{47}}
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces  Comparison of PA, $\operatorname  {AFR}_{\text  {P}}$ and $\operatorname  {AFR}_{\text  {T}}$ scores for ERM, IRM and LISA learning algorithms under different levels of shift power. The highest robustness score is emboldened for every case. PA is able to discriminate algorithms consistently and distinguish the first shifted factor, which is seen by the model during training, from the rest. \relax }}{47}{}\protected@file@percent }
\newlabel{tab:shift_comparison_table}{{4.9}{47}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Model selection}{49}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:model_selection}{{5}{49}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Model selection under controled experimental conditions}{49}{}\protected@file@percent }
\newlabel{chapter:msel_controlled}{{5.1}{49}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces REMOVEopt=adam-lr=0.0001-mf=hue-npair=FalseREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\relax }}{51}{}\protected@file@percent }
\newlabel{tab:label}{{5.1}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces REMOVEopt=adam-lr=0.0001-mf=hue-npair=TrueREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\relax }}{51}{}\protected@file@percent }
\newlabel{tab:label}{{5.2}{51}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces REMOVEopt=adam-lr=0.0001-mf=pos-npair=FalseREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\relax }}{52}{}\protected@file@percent }
\newlabel{tab:label}{{5.3}{52}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces REMOVEopt=adam-lr=0.0001-mf=pos-npair=TrueREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\relax }}{52}{}\protected@file@percent }
\newlabel{tab:label}{{5.4}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}ID model selection}{52}{}\protected@file@percent }
\citation{euligDiagViB6DiagnosticBenchmark2021}
\newlabel{def:zso_theory}{{5.2}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Blabla...\relax }}{53}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces REMOVEopt=sgd-lr=0.0001-mf=hue-npair=FalseREMOVE Test performance on increasingly shifted datasets for models selected during ERM and IRM procedures. Different validation datasets are used, and the selection capabilities of PA and validation accuracy are compared.\relax }}{54}{}\protected@file@percent }
\newlabel{tab:label}{{5.5}{54}}
\citation{kohWILDSBenchmarkIntheWild2021}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Model selection on benchmark datasets}{55}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusions}{57}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:conclusions}{{6}{57}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Theoretical Proofs and Derivations}{59}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:appendix_theory}{{A}{59}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Proof of problem formulation}{59}{}\protected@file@percent }
\newlabel{sec:proofs}{{A.1}{59}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Properties of the PA kernel}{61}{}\protected@file@percent }
\newlabel{sec:appendix_pa}{{A.2}{61}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Supplementary Results}{65}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:appendix_results}{{B}{65}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}PA as a robustness metric}{65}{}\protected@file@percent }
\newlabel{sec:appendix_results_pametric}{{B.1}{65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B.1.1}Empirical behaviour}{65}{}\protected@file@percent }
\newlabel{subsec:appendix_empirical_behaviour}{{B.1.1}{65}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Evolution of the $\beta $ optimization for a robust sample.\relax }}{65}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Evolution of the $\beta $ optimization for a non-robust sample.\relax }}{65}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Logit distributions associated with the behaviour observed in Figure \ref {fig:prediction_confidence}.\relax }}{66}{}\protected@file@percent }
\newlabel{fig:logits_confidence}{{B.3}{66}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.4}{\ignorespaces Evolution of $\beta $ optimization for different initial values for a non-robust classifier.\relax }}{66}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.5}{\ignorespaces Evolution of $\beta $ optimization for different initial values for a robust classifier.\relax }}{66}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.6}{\ignorespaces  PA and accuracy for the IMDB sentiment classification task under simple adversarial attacks. Observations are perturbed by replacing some words with positive or negative adjectives that either encourage (amplification) or discourage (contradiction) the true sentiment of the review. The attack power is defined as $2^W$, being $W$ the number of words replaced. \relax }}{67}{}\protected@file@percent }
\newlabel{fig:imdb_adversarial}{{B.6}{67}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}Adversarial setting}{67}{}\protected@file@percent }
\newlabel{sec:appendix_results_adversarial}{{B.2}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.7}{\ignorespaces PA and AFR(P) variation under increasing adversarial ratio at different perturbation norm bounds. The undefended net and several RobustBench robust models are considered against a 1000 step PGD attack.\relax }}{68}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_afrpred_pgd}{{B.7}{68}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.8}{\ignorespaces PA and AFR(P) variation under increasing adversarial ratio. T he undefended net and several RobustBench robust models are considered against a 1000 step FMN attack.\relax }}{69}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_afrpred_fmn}{{B.8}{69}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.9}{\ignorespaces Illustrative representation of the terms and posterior values constrained considered for the PA approximation. \relax }}{69}{}\protected@file@percent }
\newlabel{fig:appendix_adv_illustration}{{B.9}{69}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.10}{\ignorespaces True and approximated PA values under increasing adversarial ratio for a PGD attack with $\ell _\infty $=8/255.\relax }}{71}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_approx_pa_pgd}{{B.10}{71}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.11}{\ignorespaces True and approximated PA values under increasing adversarial ratio for a FMN attack.\relax }}{71}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_approx_pa_fmn}{{B.11}{71}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.12}{\ignorespaces Average posterior probability of the predicted class for correctly classified original samples, misclassified original samples, and misleading adversarial samples, respectively. Results have been obtained through a PGD attack with $\ell _\infty $=8/255 and sorted by increasing $\beta ^{*}$.\relax }}{72}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_distribution_pgd}{{B.12}{72}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.13}{\ignorespaces Average posterior probability of the predicted class for correctly classified original samples, misclassified original samples, and misleading adversarial samples, respectively. Results have been obtained through a FMN attack and sorted by increasing $\beta ^{*}$.\relax }}{72}{}\protected@file@percent }
\newlabel{fig:appendix_adversarial_distribution_fmn}{{B.13}{72}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.14}{\ignorespaces Comparison of FMN and PGD attacks using probability-based distances.\relax }}{73}{}\protected@file@percent }
\newlabel{fig:comparison_prob_metrics}{{B.14}{73}}
\@writefile{lof}{\contentsline {figure}{\numberline {B.15}{\ignorespaces Comparison of FMN and PGD attacks using feature-space-based distances.\relax }}{73}{}\protected@file@percent }
\newlabel{fig:comparison_feat_metrics}{{B.15}{73}}
\citation{euligDiagViB6DiagnosticBenchmark2021}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Dataset reference}{74}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sec:datasets}{{C}{74}}
\newlabel{def:diagvib6_experiments}{{C}{74}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Robustness assessment}{75}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {C.1}{\ignorespaces  Image factors associated to each of the environments considered in this experiment. CC and LC account for 'centered center' and 'centered low', respectively. \relax }}{75}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Model selection}{75}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2.1}Controlled conditions}{75}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {C.2}{\ignorespaces  Image factors associated to each of the environments considered in this experiment. CC and UL account for 'centered center' and 'upper left', respectively. \relax }}{75}{}\protected@file@percent }
\newlabel{ds:hue_test}{{C.2}{75}}
\@writefile{lot}{\contentsline {table}{\numberline {C.3}{\ignorespaces  Image factors associated to each of the environments considered in this experiment. CC and UL account for 'centered center' and 'upper left', respectively. \relax }}{76}{}\protected@file@percent }
\newlabel{ds:pos_test}{{C.3}{76}}
\@writefile{lot}{\contentsline {table}{\numberline {C.4}{\ignorespaces  Image factors associated with each of the environments considered in this experiment. CC and UL account for 'centered center' and 'upper left', respectively. \relax }}{76}{}\protected@file@percent }
\newlabel{ds:pos_test}{{C.4}{76}}
\@writefile{lot}{\contentsline {table}{\numberline {C.5}{\ignorespaces  Image factors associated with each of the environments considered in this experiment. UL, LR, UR and CC account for 'upper left', 'lower right', 'upper left' and 'centered center', respectively. \relax }}{76}{}\protected@file@percent }
\newlabel{ds:pos_test}{{C.5}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C.2.2}ID model selection}{77}{}\protected@file@percent }
\newlabel{def:zgo_experiments}{{C.2.2}{77}}
\newlabel{def:1_cgo_experiments}{{C.2.2}{77}}
\newlabel{def:2_cgo_experiments}{{C.2.2}{77}}
\newlabel{def:3_cgo_experiments}{{C.2.2}{77}}
\newlabel{def:zso_experiments}{{C.2.2}{78}}
\@writefile{lot}{\contentsline {table}{\numberline {C.6}{\ignorespaces  Image factors associated to each of the environments considered in test datasets, excluding the predicted and learned factors in which the shortcut or generalization opportunities are encoded. CC and CR stand for 'center center' and 'upper left', respectively. \relax }}{78}{}\protected@file@percent }
\newlabel{tab:sogo_test}{{C.6}{78}}
\bibstyle{plain}
\bibdata{bibliography}
\bibcite{Addepalli2022ScalingAT}{1}
\bibcite{arjovskyInvariantRiskMinimization2020}{2}
\bibcite{arjovskyWassersteinGAN2017}{3}
\bibcite{AthalyeC018}{4}
\bibcite{baiRecentAdvancesAdversarial2021}{5}
\bibcite{blanchardGeneralizingSeveralRelated}{6}
\bibcite{bovierStatisticalMechanicsDisordered2012}{7}
\bibcite{boydConvexOptimization2004}{8}
\bibcite{buhmannDataScienceAlgorithms2022}{9}
\bibcite{buhmannInformationTheoreticModel2010}{10}
\bibcite{buhmannPosteriorAgreementModel2022}{11}
\bibcite{buhmannInformationTheoreticModel}{12}
\bibcite{carliniEvaluatingRobustnessNeural2017}{13}
\bibcite{casellaStatisticalInference2002}{14}
\bibcite{chehreghaniInformationTheoreticModel}{15}
\bibcite{cohenCertifiedAdversarialRobustness2019}{16}
\bibcite{croceRobustBenchStandardizedAdversarial2021a}{17}
\bibcite{dasKeepingBadGuys2017}{18}
\bibcite{engstrom2019adversarial}{19}
\bibcite{euligDiagViB6DiagnosticBenchmark2021}{20}
\bibcite{goodfellowExplainingHarnessingAdversarial2015}{21}
\bibcite{grunwaldMinimumDescriptionLength2019}{22}
\bibcite{guoComprehensiveEvaluationFramework2023}{23}
\bibcite{gutIntermediateCourseProbability2009}{24}
\bibcite{resnet50}{25}
\bibcite{hoDenoisingDiffusionProbabilistic2020}{26}
\bibcite{ilyasAdversarialExamplesAre2019}{27}
\bibcite{logicofscience}{28}
\bibcite{jimenezInductiveBiasDeep}{29}
\bibcite{khoslaUndoingDamageDataset2012}{30}
\bibcite{kingmaAdamMethodStochastic2017}{31}
\bibcite{kohWILDSBenchmarkIntheWild2021}{32}
\bibcite{krizhevskyLearningMultipleLayers}{33}
\bibcite{lecun1998mnist}{34}
\bibcite{liLearningGeneralizeMetaLearning2018}{35}
\bibcite{liReviewAdversarialAttack2022}{36}
\bibcite{liangComprehensiveSurveyTestTime2023}{37}
\bibcite{liuOutOfDistributionGeneralizationSurvey2023}{38}
\bibcite{m.bishopPatternRecognitionMachine2006}{39}
\bibcite{maas2011learning}{40}
\bibcite{madryDeepLearningModels2019}{41}
\bibcite{miyatoVirtualAdversarialTraining2018}{42}
\bibcite{muandetDomainGeneralizationInvariant2013}{43}
\bibcite{n.vapnikNatureStatisticalLearning2000}{44}
\bibcite{p.murphyProbabilisticMachineLearning2022}{45}
\bibcite{peiMultiAdversarialDomainAdaptation}{46}
\bibcite{pintorFastMinimumnormAdversarial2021}{47}
\bibcite{quinonero-candelaDatasetShiftMachine2009}{48}
\bibcite{ruderOverviewGradientDescent2017}{49}
\bibcite{rumelhartLearningRepresentationsBackpropagating1986}{50}
\bibcite{sanh2019distilbert}{51}
\bibcite{schmidtAdversariallyRobustGeneralization2018}{52}
\bibcite{shenWassersteinDistanceGuided2018}{53}
\bibcite{simonyanVeryDeepConvolutional2015}{54}
\bibcite{szegedyIntriguingPropertiesNeural2014}{55}
\bibcite{torralbaUnbiasedLookDataset2011}{56}
\bibcite{tsiprasRobustnessMayBe2019}{57}
\bibcite{voulodimosDeepLearningComputer2018}{58}
\bibcite{wangMetaFineTuningNeural2020}{59}
\bibcite{wangGeneralizingUnseenDomains2022}{60}
\bibcite{wangGeometricalApproachEvaluate2023}{61}
\bibcite{wangBetterDiffusionModels2023}{62}
\bibcite{wang2023betterdiffusionmodelsimprove}{63}
\bibcite{wengEvaluatingRobustnessNeural2018}{64}
\bibcite{WongRK20}{65}
\bibcite{xiaoGeneratingAdversarialExamples2019}{66}
\bibcite{yaoImprovingOutofDistributionRobustness2022}{67}
\bibcite{yuPACSDatasetPhysical2022}{68}
\bibcite{yunCutMixRegularizationStrategy2019}{69}
\bibcite{BMVC2016_87}{70}
\bibcite{zhangTheoreticallyPrincipledTradeoff2019}{71}
\bibcite{zhangMixupEmpiricalRisk2018}{72}
\bibcite{zhouDomainGeneralizationSurvey2022}{73}
\gdef \@abspage@last{93}
